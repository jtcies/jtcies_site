---
title: "Comparing NBA teams from the past 20 years"
author: "Joe Ciesielski"
date: '2018-09-18'
tags:
  - Shiny
  - r
  - Elo
  - NBA
output: html_document
draft: true
---

```{r, include=FALSE}

knitr::opts_chunk$set(fig.align = 'center', fig.width = 6, fig.asp = 0.618,
                      echo = FALSE, warning = FALSE, message = FALSE)


```

With the NBA season fast-approaching (maybe not fast enough for some of us), I wanted to play around with some NBA data and explore teams from recent history. My beloved Philadelphia 76ers have made a remarkable rise in the past two years, going from one of the worst teams in history to a contender for the conference championship, so their might be some bragging rights invovled in this too. 

## What's the best way to rate teams?

The first step was to determine the best empirical measure of a team's ability. The website [Fivethirtyeight][1] uses Elo for their ratings. They have an excellent primer on Elo overall as well some specific decisions they made in creating their NBA rankings as well. They also publish complete Elo ratings since the start of the NBA, but I wanted to create the ratings mayself (while using their ratings as a comparison benchmark). 

For those not familar, Elo is a measure of relative ability. A rating of 1500 is average; a team gains points when they win and drops points after a loss. The points gained or lost are relative to the gap between the teams: a team will gain a lot of points for beating a team with a much higher rating but may only gain a few for beating a team with a lower rating. 

You can look at how a team's Elo changes over time, but that has been done a lot. I thought it would be fun to use Elo to see how any two teams would match up on any date. I created a Shiny application that does both; the rest of this post walks through the process of creating that application. In a later post, I'll take a look at some things we can glean from this data. 

## Creating the Elo tables

### Getting the data

First we need to get the data. [Basketball Reference][2] is the go-to place for any NBA related data. It's organized in a way that makes it possible to scrape the data. 

I wrote a function to scrape this data. The website is organized by month and year. I wanted to go back about 20 years, but one thing that made this tricky a change in format after the 2000 season (BR added a 'start time' column). The function below parses the tables that include data, teams, and final score.

```{r, eval = FALSE, echo = TRUE}
scrape_br <- function(url) {
# function to scrape the data and organize it into a data frame
  # table from older years missing start time
  old_format_years <- "1997|1998|1999|2000"
  old_format <- if_else(grepl(old_format_years, url), TRUE, FALSE) 
  table_names <- c("date", "start_time", "visitor", "visitor_pts",
                   "home", "home_pts", "link", "ot", "attendance",
                   "notes")
  if(old_format) num_col <- 9 else num_col <- 10
  # get the table
  tmp <- url %>% 
    read_html() %>% 
    html_nodes(".right , .left , .center") %>% 
    html_text()
  # prep to read as csv
  tmp <- gsub(",", "", tmp) # remove commas for reading as csv
  # add a comma to the end of each field
  tmp <- paste0(tmp, ",")
  # start a new row after each 9/10 element depending on season
  new_rows <- seq(0, length(tmp), by = num_col)
  tmp[new_rows] <- paste0(tmp[new_rows], "\n")
  # collapse to a chacter string then read as csv
  # convert all cols to character, read.csv was reading some in correctly
  dat <- paste0(tmp, collapse = "") %>% 
    read.csv(text = .,
             colClasses = rep("character", num_col)) %>% 
    filter(PTS != "") # remove rows w/o data
  # clean up column names
  if(old_format) {
    names(dat) <- table_names[table_names != "start_time"]
  } else {
    names(dat) <- table_names
  }
  dat[!is.na(names(dat))]
}

```

This gets the games for each month. Then we map this over all of the months for the past 20 years and combine it into one table. 

```{r, eval = FALSE, echo = TRUE}

# create all combinations of months and years
months <- c("october", "november", "december", "january", "february", 
            "march", "april", "may", "june")

years <- seq(1997, 2018, by = 1)

season_months <- expand.grid(years, months)

# create a list of urls for scraping data
br_urls <- paste0(
  "https://www.basketball-reference.com/leagues/NBA_", 
  season_months$Var1, 
  "_games-",
  season_months$Var2,
  ".html"
)

# get only valid urls and scrape
br_dat <- map(br_urls, ~ifelse(RCurl::url.exists(.), ., NA)) %>% 
  .[!is.na(.)] %>% 
  map(., scrape_br) %>% 
  bind_rows()
```

### Calculating Elo



[1]: https://www.fivethirtyeight.com
[2]: https://www.basketball-reference.com