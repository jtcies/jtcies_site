## Simple questions, complex answers

The education and social sector are complex systems. When we need to make decisions about those systems, such as which schools to send our children to or which programs to fund, we often focus on the outputs of those systems, rather than what creates those outcomes. When decisions based on those outcomes get made over and over again, the systems will naturally optimize for those outcomes. If we do not examine the system carefully, this will have unintended consequences that are frequently the opposite of what we were trying to achieve. We need to dig into our systems to understand how they produce the outcomes we see, and get really clear about what we are trying to optimize for and why. 

## school ratings

Mother Jones recently published a piece on school ratings, families' housing decisions, and segregation. Rating systems have become common on real estate websites, and factor heavily into parents' decision about which neighborhoods are desirable. 

Because these ratings are based mostly on test scores, and test scores are highly correlated with the racial make-up of schools, they de facto exacerbate racial segregation in schools and neighborhoods. Couple this with more direct forms of racism, it can be a really pernicious problem to solve. 

Schools are busy places. Everyday teachers and staff make thousands of decisions that impact the lives of students, including what topics to teach, how to deal with student behaviors, and what extracurriculars to offer. Test scores are intended to represent one part of a schools effectiveness, but all of these other things are part of how we think of school quality. Those don't show up in the rankings.

Cathy O'Neill makes a similar point about college rankings in U.S. News. The rankings highly value things like how competitive acceptance (i.e. low acceptance rates), student-teacher ratios, and the percentage of students who gave to their alma mater after graduation. Those things are only loosely associated with what we would define as quality in higher education. They are closely related, however, to the amount of resources that schools have. Schools with the highest ranking get more resources through top-performing students and professors and greater contributions from alumni, therefore increasing their rating even more. Similarly, lower ranked schools have resources taken away from them, making their ratings fall more. 

## Thinking in Systems

The relationship between these ratings and school resources are examples what Donnella Meadows calls reinforcing feedback loops. A simple example of a reinforcing feedback loop is an interest-bearing bank account. You put money in the account, and without doing anything it earns more money. The greater amount of money in that account generates even more money and so on. 

However, reinforcing feedback loops, especially when they're not fully understood, have the tendency to spiral out of control. The amount of resources a school has is like a bank outcome. The output of that bank account is the rating, but families decisions operate like the interest, bringing greater resources to those schools that have the most, and less to those that have limited resources. 

We need to make sure we spend more time thinking about how schools create the outcomes we see, and what aspects of quality we want to optimize for.

## Rigorous Evaluations 

Results for America recently published a piece called "Moneyball for Workforce Development". The gist is that in the reauthorization of WIOA, the federal government should dedicate more money to rigorous evaluation. Rigorous evaluation in this case is synonymous with randomized control trials. 

Randomized control trials take the premise that randomization of individuals to a treatment or program factors out differences between treatment and control, allowing a unimpended view into the effectivies of the initiative. Inherent in RCTs is the idea that measuring outcomes will tell you all you need to know; you don't need to **what** the program does, because the outcomes alone will tell you whether it worked or not.

The report does argue that more innovative outcome measures are needed, and it nowhere suggests that we should not evaluate implementation alongside outcomes. However, I believe that relying so heavily on RCTs for evaluation can lead to optimizing for things that have unintended, potentially negative consequences. 

For example, it seems likely that optimizing for job placement post program would lead to students being placed in low-wage jobs with little opportunity for advancement. Optimizing for education credentials may lead to biased program acceptance, leaving participants who struggle with basic literacy skills out of the opportunity altogether - if you randomize **after** program acceptance, you wouldn't know how that changes outcomes.

In addition to more rigorous forms of evaluation, we need to invest in evaluation which is allows view into what is actually happening in these various intiatives. 

## Conclusion

We have to be really careful, when dealing with complex systems, how we are building the kinds of systems we want. Systems with reinforcing feedback loops can very easily create the opposite outcomes we are looking for if we are not careful. 
